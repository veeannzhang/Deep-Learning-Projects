{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_1_starter.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rbVvdjpZx_V0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Starter code for assignment 1\n",
        "This notebook contains the starter code for assignment 1, with unfinished sections for your to complete. Please work through it, and add your code where instructed. There are short-answer writen questions as well at the bottom of the notebook.\n",
        "\n",
        "When you're finished, save and submit your completed notebook, including the output from your final run."
      ]
    },
    {
      "metadata": {
        "id": "Dm6aPTITx_V1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display figures inline (rather than opening a new window)\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# For compatibility between Python 2 and 3\n",
        "from six.moves import urllib\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit    \n",
        "\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0cAubD3ex_V6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download the mini-cifar data\n",
        "Understand the format, and visualize images."
      ]
    },
    {
      "metadata": {
        "id": "wS-J2deox_V7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source = \"https://storage.googleapis.com/jbgordon/mini-cifar.npz\"\n",
        "dest = \"mini-cifar.npz\"\n",
        "urllib.request.urlretrieve(source, dest)\n",
        "loaded = np.load(open(dest))\n",
        "examples, labels, class_names = loaded[\"X\"], loaded[\"y\"], loaded[\"class_names\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZzc4KW6x_V-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's look at the format of an image. Below we see the shape of our data is n_examples x 32 x 32 x 3. The dimensions correspond to:\n",
        "* Number of examples.\n",
        "* Rows in an image.\n",
        "* Columns in an image.\n",
        "* Color channels (R,G,B)."
      ]
    },
    {
      "metadata": {
        "id": "aNEHPD1Bx_V_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "examples.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W_W_0FuSx_WD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's inspect the labels."
      ]
    },
    {
      "metadata": {
        "id": "I5IcHirmx_WE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qkE3LRrTx_WH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This dataset is balanced (contains an equal number of examples of each class). We've stored these in *class_names* for convenience."
      ]
    },
    {
      "metadata": {
        "id": "9k2AdhuXx_WJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stats.itemfreq(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UGNf86E_x_WM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "at09Zp-lx_WP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's display a few examples from each class. "
      ]
    },
    {
      "metadata": {
        "id": "iiQSnYBSx_WP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "examples_per_class = 5\n",
        "# We'll create a grid of plots, then populate them with images\n",
        "f, ax = plt.subplots(examples_per_class, num_classes)\n",
        "for class_idx in range(len(class_names)):\n",
        "    # Find the indicies in the examples for this class\n",
        "    matching_indices = np.where(labels == class_idx)[0]\n",
        "    for example_n in range(examples_per_class):\n",
        "        # The images are stored as floats but need to be converted to ints\n",
        "        # so they display properly\n",
        "        example = examples[matching_indices[example_n]].astype('uint8')\n",
        "        ax[example_n, class_idx].imshow(example)\n",
        "        ax[example_n, class_idx].axis('off')\n",
        "        plt.axis('off')\n",
        "        if example_n == 0:\n",
        "            ax[example_n, class_idx].set_title(class_names[class_idx])\n",
        "f.set_size_inches(8,4)\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ars2bSNxx_WV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In case that code is a bit of a handful, here's a block you can use to display a single image."
      ]
    },
    {
      "metadata": {
        "id": "KSVTFwuIx_WX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "plt.imshow(examples[idx].astype('uint8'))\n",
        "plt.title(class_names[labels[idx]])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDiU5c_dx_Wb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "metadata": {
        "id": "uwlCj431x_Wd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Flatten the images (reshaping from n_examples x 32 x 32 x 3 to n_examples x 3072)\n",
        "examples = np.reshape(examples, (examples.shape[0], -1))\n",
        "examples.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ER_i7NgNx_Wh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll divide the data into train and test."
      ]
    },
    {
      "metadata": {
        "id": "25czW8i8x_Wh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A helpful utility to create balanced splits\n",
        "# See: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\n",
        "sss = StratifiedShuffleSplit(train_size=1200, n_splits=1, \n",
        "                             test_size=200, random_state=0)  \n",
        "\n",
        "for train_index, test_index in sss.split(examples, labels):\n",
        "    X_train, X_test = examples[train_index], examples[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjSdI-Isx_Wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Train examples: %d\" % X_train.shape[0])\n",
        "print(\"Test examples: %d\" % X_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-R1I9Q4ex_Wl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1) Complete the kNN classifer\n",
        "You'll need to modify it to a) compute distance between examples, and b) to work with different values of k."
      ]
    },
    {
      "metadata": {
        "id": "GOz1uHtix_Wn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class KNNClassifier(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def train(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Train the model.\n",
        "\n",
        "        Inputs:\n",
        "        - X_train: A numpy array of shape (train_examples, features) \n",
        "        containing the training data.\n",
        "        - y_train: A numpy array of shape (train_examples,) \n",
        "        containing the training labels.\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "    \n",
        "    def distance_matrix(self, X_test):\n",
        "        \"\"\"\n",
        "        Calculate a distance matrix.\n",
        "\n",
        "        Inputs:\n",
        "        - X: A numpy array of shape (test_examples, pixels) containing the test data.\n",
        "\n",
        "        Returns:\n",
        "        - distances: A numpy array of shape (test_examples, train_examples). \n",
        "        Distances[i, j] gives the Euclidean distance between the ith testing point \n",
        "        and the jth training point. \n",
        "        \"\"\"\n",
        "        test_size = X_test.shape[0]\n",
        "        train_size = self.X_train.shape[0]\n",
        "     \n",
        "        # Rows give the distance from a test example to every training example\n",
        "        distance_matrix = np.zeros((test_size, train_size)) \n",
        "        \n",
        "        ########################################################################\n",
        "        # TODO: Modify the code below.\n",
        "        # \n",
        "        # Calculate the Euclidian distance between every ith test example\n",
        "        # and jth training example, then store the result in the distance\n",
        "        # matrix.\n",
        "        # \n",
        "        # As implemented, this method currently computes a random distance.\n",
        "        # Repalce that with Euclidian.\n",
        "        # \n",
        "        # (Aside, this pair of nested for loops woefully inefficient, and \n",
        "        # can be improved by using vectorized operations in NumPy. \n",
        "        # Runtime performance is not important for this assignment).\n",
        "        # \n",
        "        ########################################################################\n",
        "        length = self.X_train[0].shape[0] # Get the number of elements in each sample\n",
        "\n",
        "        for i in range(test_size):\n",
        "            for j in range(train_size):\n",
        "                \n",
        "                # Calculate the distance between X_test[i] and self.X_train[j]\n",
        "                distance = np.sum((X_test[i]-self.X_train[j])**2)**0.5 # Vectorized calculation\n",
        "               \n",
        "                # Store the result in the distance matrix.\n",
        "                distance_matrix[i,j] = distance\n",
        "\n",
        "        return distance_matrix\n",
        "    \n",
        "    def predict(self, X_test, distance_matrix, k=1):\n",
        "        \"\"\"\n",
        "        Predict labels for the testing data.\n",
        "\n",
        "        Inputs:\n",
        "        - X_test: A numpy array of shape (test_examples, features) containing the test data.\n",
        "        - distance_matrix: A previously computed distance matrix, described above.\n",
        "        \n",
        "        Returns:\n",
        "        - predictions: A numpy array of shape (test_examples,). \n",
        "        predictions[i] contains the predicted label for the ith testing example. \n",
        "        \"\"\"\n",
        "        \n",
        "        # To make a prediction, we'll find the k-nearest training examples\n",
        "        # to a test example in our distance matrix, and return their \n",
        "        # most common label as our prediction. Ties may be broken randomly.\n",
        "        \n",
        "        ########################################################################\n",
        "        # TODO: Modify the code below.\n",
        "        #\n",
        "        # As written, this method works properly for k=1.\n",
        "        # Improve it so it works for other values of k.\n",
        "        #\n",
        "        # **Hints**\n",
        "        # \n",
        "        # We currently use np.argmin to find the index of the element with minimum \n",
        "        # distance. See the doc for ```np.argsort``` to do something similar \n",
        "        # for multiple elements. \n",
        "        # https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html\n",
        "        # \n",
        "        ########################################################################\n",
        "    \n",
        "        test_size = X_test.shape[0] # Number of test set elements\n",
        "        predictions = np.zeros(test_size) # Initialize an empty array for predicted labels\n",
        "        \n",
        "        for i in range(test_size):\n",
        "            row = distance_matrix[i]\n",
        "            \n",
        "            # This finds the index of the k-nearest training example.\n",
        "            sorted_idx = np.argsort(row) # Return the indices that would sort the array\n",
        "      \n",
        "            k_nearest_idx = sorted_idx[:k] # Return the indices of the k smallest distances\n",
        "            \n",
        "            # Look up the correspond label. \n",
        "            tmp_labels = np.zeros(k) # Initialize an empty array to store the labels of the neighbors\n",
        "            for j in range(k):\n",
        "              tmp_labels[j] = self.y_train[k_nearest_idx[j]] # Store labels for k-nearest neighbors\n",
        "              \n",
        "            label = stats.mode(tmp_labels)[0][0]\n",
        "                          \n",
        "            # Store the result\n",
        "            predictions[i] = label\n",
        "            \n",
        "            # Above is our prediction for this testing example. \n",
        "            # This works properly for k=1. You'll need to modify it\n",
        "            # to work with other values of k.\n",
        "            \n",
        "        return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n42_mwvbx_Wp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = KNNClassifier()\n",
        "classifier.train(X_train, y_train)\n",
        "distance_matrix = classifier.distance_matrix(X_test) \n",
        "predictions = classifier.predict(X_test, distance_matrix, k=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtpSgnyLx_Wu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(predicted, actual):\n",
        "    correct = np.sum(predicted == actual)\n",
        "    total = predicted.shape[0]\n",
        "    accuracy = float(correct) / total\n",
        "    return accuracy\n",
        "\n",
        "acc = accuracy(predictions, y_test)\n",
        "print('Accuracy: %.2f' % (acc))\n",
        "\n",
        "if acc > 0.50:\n",
        "    print (\"Congrats! Your classifier is working well on this data.\")\n",
        "else:\n",
        "    print (\"Keep at it.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w0vDANOtx_W4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2) Short answer questions\n",
        "\n",
        "Just a few sentences each is fine. Please write your answers in-line below."
      ]
    },
    {
      "metadata": {
        "id": "Ero22eyvx_W6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1) Is the kNN classifier invariant to image orientation? E.g., what would happen if we used the model to make a prediction on a picture of a car that happened to upside down (assuming the training set contained images of cars right side up).\n",
        "\n",
        "KNN classifier is not invariant to image orientation. When we rotate the image (or mirror it), the pixel values are all re-ordered when we flatten pixel matrix into an array. The input features would be very different from normal right side up car features for training. Therefore, when we train the classifier with cars right side up, the classifier would very likely not be able to recognize the car upside down.\n",
        "\n",
        "2) What are the pros/cons of using raw pixel values as features? It is sensisble to use them when working with images? Why or why not?\n",
        "\n",
        "If using raw pixel values as features, it will require a CNN and much more computational resources to train the network. If we have a high level of understanding of the problem, it is not sensible to use raw pixels when working with images because you can use feature engineering to solve the problem with less data more elegantly. \n",
        "\n",
        "3) Is it important to normalize the data (e.g., by subtracting the mean and dividing by the standard deviation) when working with kNN? Why or why not?\n",
        "\n",
        "It is important to normalize the data because KNN uses Euclidean distance for classification. For example, in a 2-dimensional dataset, if the range of one dimension is significantly different from the other dimension, the KNN algorithm may produce incorrect classification result."
      ]
    },
    {
      "metadata": {
        "id": "3kzmvJdsdQ4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3) Collect your own dataset\n",
        "\n",
        "In this section, you'll write code to:\n",
        "\n",
        "* Download a small dataset (say, of 5 images - these can be of anything you like) from the web. You can use the urllib library above to download them.\n",
        "\n",
        "* Next, convert these images into an appropriate format in NumPy.\n",
        "\n",
        "* Finally, use your completed classifier above to train a model on these images and make predictions. Report your accuracy."
      ]
    },
    {
      "metadata": {
        "id": "1U4mRv0BdPOy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Your code here.\n",
        "from PIL import Image\n",
        "import urllib, cStringIO\n",
        "urls = ['http://www.bas-uk.com/sites/default/files/suri1_0.jpg', # Alpaca\n",
        "        'http://www.bas-uk.com/sites/default/files/alpaca2001_1.jpg', # Alpaca\n",
        "        'https://hivemodern.com/public_resources/vl38-table-lamp-vilhelm-lauritzen-louis-poulsen.jpg', # Lamp\n",
        "        'https://gabbyhome.com/wp-content/uploads/SCH-153745-150x150.jpg', # Lamp\n",
        "        'https://www.openherd.com/userPhotos/Large/2015_635666082152776416.jpg'] # Alpaca "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EjcPvw5YW6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Labels = np.array([1, 1, 0, 0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L13a28PrIhy6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i in urls:\n",
        "  f = cStringIO.StringIO(urllib.urlopen(i).read())\n",
        "  img = Image.open(f)\n",
        "  img.load()\n",
        "  data.append(np.asarray(img, dtype = 'int32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7jgjwU7Xd25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_kNGAYgVaxI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aD6JtE49LY5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stats.itemfreq(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4IAjAdqZFT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Class_names = (['Lamp', 'Alpaca'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RtofzFSAaCnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Flatten the images (reshaping from n_examples x 32 x 32 x 3 to n_examples x 3072)\n",
        "data = np.reshape(data, (data.shape[0], -1))\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLwwyjnoaS5i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train1 = data[0:4]\n",
        "X_test1 = data[4:]\n",
        "y_train1 = Labels[0:4]\n",
        "y_test1 = Labels[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDLHo8KqapGC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Train examples: %d\" % X_train1.shape[0])\n",
        "print(\"Test examples: %d\" % X_test1.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOpkgLdYblz0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = KNNClassifier()\n",
        "classifier.train(X_train1, y_train1)\n",
        "distance_matrix = classifier.distance_matrix(X_test1) \n",
        "predictions = classifier.predict(X_test1, distance_matrix, k=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOhxpjS6bqn7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(predicted, actual):\n",
        "    correct = np.sum(predicted == actual)\n",
        "    total = predicted.shape[0]\n",
        "    accuracy = float(correct) / total\n",
        "    return accuracy\n",
        "\n",
        "acc = accuracy(predictions, y_test)\n",
        "print('Accuracy: %.2f' % (acc))\n",
        "\n",
        "if acc > 0.50:\n",
        "    print (\"Congrats! Your classifier is working well on this data.\")\n",
        "else:\n",
        "    print (\"Keep at it.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYCRbXMDx_W7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When you're finished, save your notebook (including the output from your final run) and submit your notebook on CourseWorks. Your completed notebook should run end-to-end with no user intervention required."
      ]
    }
  ]
}